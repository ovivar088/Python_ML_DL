{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import ssl\n",
    "from download_mnist import load\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\myaku\\miniconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\myaku\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\myaku\\miniconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = (5,5))\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = (5,5))\n",
    "        self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 120, kernel_size = (4,4))\n",
    "\n",
    "        self.L1 = nn.Linear(256,120)\n",
    "        self.L2 = nn.Linear(120,84)\n",
    "        self.L3 = nn.Linear(84,10)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
    "        \n",
    "        self.act = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #Layer1\n",
    "        x = self.conv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        #Layer2\n",
    "        x = self.conv2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        #Layer3\n",
    "        x = self.conv3(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        #Layer4\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.L2(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        #Layer5\n",
    "        x = self.L3(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    count = 0\n",
    "    lossFunc = nn.NLLLoss()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = lossFunc(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(\n",
    "                epoch,  loss.item()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def test( model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# print('==> Preparing data..')\n",
    "# x_train, y_train, x_test, y_test = load()\n",
    "import torchvision.datasets as datasets\n",
    "trainSet = datasets.MNIST(root='data',train=True,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "testSet = datasets.MNIST(root='data',train=False,transform=torchvision.transforms.ToTensor(),download=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(\"Optimizer: SGD \\n\")\n",
    "time0 = time.time()\n",
    "# Training settings\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "lr = 0.05\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(100)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainSet,batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testSet,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "model = LeNet().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train( model, device, train_loader, optimizer, epoch)\n",
    "    test( model, device, test_loader)\n",
    "\n",
    "time1 = time.time() \n",
    "print ('Training and Testing time for SGD: %s seconds ' % (time1-time0), \"\\n\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimizer: SGD \n",
      "\n",
      "Train Epoch: 1 \tLoss: 0.073226\n",
      "\n",
      "Test set: Average loss: 0.0844, Accuracy: 9728/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 \tLoss: 0.036375\n",
      "\n",
      "Test set: Average loss: 0.0550, Accuracy: 9819/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 \tLoss: 0.074217\n",
      "\n",
      "Test set: Average loss: 0.0453, Accuracy: 9848/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 \tLoss: 0.049258\n",
      "\n",
      "Test set: Average loss: 0.0451, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 \tLoss: 0.036656\n",
      "\n",
      "Test set: Average loss: 0.0488, Accuracy: 9836/10000 (98%)\n",
      "\n",
      "Training and Testing time for SGD: 81.41930413246155 seconds  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(\"Optimizer: Adagrad \\n\")\n",
    "time0 = time.time()\n",
    "# Training settings\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "lr = 0.05\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(100)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainSet,batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testSet,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "model = LeNet().to(device)\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train( model, device, train_loader, optimizer, epoch)\n",
    "    test( model, device, test_loader)\n",
    "\n",
    "time1 = time.time() \n",
    "print ('Training and Testing time for Adagrad: %s seconds ' % (time1-time0), \"\\n\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimizer: Adagrad \n",
      "\n",
      "Train Epoch: 1 \tLoss: 0.084327\n",
      "\n",
      "Test set: Average loss: 0.0932, Accuracy: 9712/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 \tLoss: 0.024540\n",
      "\n",
      "Test set: Average loss: 0.0603, Accuracy: 9793/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 \tLoss: 0.084185\n",
      "\n",
      "Test set: Average loss: 0.0557, Accuracy: 9825/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 \tLoss: 0.049981\n",
      "\n",
      "Test set: Average loss: 0.0589, Accuracy: 9795/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 \tLoss: 0.017290\n",
      "\n",
      "Test set: Average loss: 0.0434, Accuracy: 9858/10000 (99%)\n",
      "\n",
      "Training and Testing time for Adagrad: 114.32223296165466 seconds  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(\"Optimizer: RMSprop \\n\")\n",
    "time0 = time.time()\n",
    "# Training settings\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "lr = 0.05\n",
    "save_model = False\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(100)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainSet,batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testSet,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "model = LeNet().to(device)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=lr, eps=0.1)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train( model, device, train_loader, optimizer, epoch)\n",
    "    test( model, device, test_loader)\n",
    "\n",
    "time1 = time.time() \n",
    "print ('Training and Testing time for RMSprop: %s seconds ' % (time1-time0), \"\\n\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimizer: RMSprop \n",
      "\n",
      "Train Epoch: 1 \tLoss: 0.075394\n",
      "\n",
      "Test set: Average loss: 0.1315, Accuracy: 9589/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 \tLoss: 0.044737\n",
      "\n",
      "Test set: Average loss: 0.0649, Accuracy: 9791/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 \tLoss: 0.062914\n",
      "\n",
      "Test set: Average loss: 0.0593, Accuracy: 9805/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 \tLoss: 0.060107\n",
      "\n",
      "Test set: Average loss: 0.0605, Accuracy: 9807/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 \tLoss: 0.028163\n",
      "\n",
      "Test set: Average loss: 0.0457, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Training and Testing time for RMSprop: 97.56442308425903 seconds  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(\"Optimizer: Adam \\n\")\n",
    "time0 = time.time()\n",
    "# Training settings\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "lr = 0.05\n",
    "save_model = False\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(100)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainSet,batch_size=batch_size,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testSet,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "model = LeNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train( model, device, train_loader, optimizer, epoch)\n",
    "    test( model, device, test_loader)\n",
    "\n",
    "time1 = time.time() \n",
    "print ('Training and Testing time for Adam: %s seconds ' % (time1-time0), \"\\n\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimizer: Adam \n",
      "\n",
      "Train Epoch: 1 \tLoss: 0.589719\n",
      "\n",
      "Test set: Average loss: 0.4916, Accuracy: 8482/10000 (85%)\n",
      "\n",
      "Train Epoch: 2 \tLoss: 0.449713\n",
      "\n",
      "Test set: Average loss: 0.4635, Accuracy: 8547/10000 (85%)\n",
      "\n",
      "Train Epoch: 3 \tLoss: 0.402128\n",
      "\n",
      "Test set: Average loss: 0.4421, Accuracy: 8550/10000 (86%)\n",
      "\n",
      "Train Epoch: 4 \tLoss: 0.692701\n",
      "\n",
      "Test set: Average loss: 0.4638, Accuracy: 8551/10000 (86%)\n",
      "\n",
      "Train Epoch: 5 \tLoss: 0.597164\n",
      "\n",
      "Test set: Average loss: 0.4484, Accuracy: 8526/10000 (85%)\n",
      "\n",
      "Training and Testing time for Adam: 99.66939949989319 seconds  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}